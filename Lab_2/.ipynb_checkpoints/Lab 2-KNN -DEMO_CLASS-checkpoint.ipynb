{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571f22c1",
   "metadata": {},
   "source": [
    "# LAB 2- Machine learning Use Case-KNN with Iris Dataset \n",
    "# 1. Step-by-Step KNN Implementation:\n",
    "# 2. Import necessary libraries\n",
    "# 3. Load dataset\n",
    "# 4. Split the data into training and test sets\n",
    "# 5. Scale the data\n",
    "# 6. Train the KNN model\n",
    "# 7. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c11c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52ba948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset stored in path Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8e8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print iris \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76180dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count species in iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f306cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cebd4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorical data to numerical data\n",
    "#in this dataset, species is categorical data -hence need to change tu numerical using albel encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "iris.species=le.fit_transform(iris.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d281238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view the first 5 rows of data in iris\n",
    "#species has changes to numerical value represented by 0,1 and 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f26ef7-99eb-4e80-b9ed-5985ec35f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view the last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71beed9",
   "metadata": {},
   "source": [
    "# SPLIT BETWEEN TARGET AND FEATURE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b03f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features list\n",
    "#species will be the target hence we need to drop it from features \n",
    "X=iris.drop('species', axis=1)\n",
    "#target-assigned teh target to y \n",
    "y=iris.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c13bb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print X after drop species \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6defadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print y after set as target \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1154fa",
   "metadata": {},
   "source": [
    "# Split the data into training and test sets\n",
    "At the begining you will split your data into a train and a test set. So you will have X_train and y_train for the features and target values you will use during the training of your model. And you will have X_test and y_test for the features and target values you will use for the final evaluation of your model.\n",
    "\n",
    "X is a matrix of the features values, each column being one feature, and being known values.\n",
    "\n",
    "Each column of X is an independant variable.\n",
    "\n",
    "y is a vector of the target values, being the values you want to try to predict.\n",
    "\n",
    "y has only one column and is the dependant/target variable.\n",
    "\n",
    "A row in X anf y is one data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b73bf-63ab-4572-afff-829f3c10a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into trainning and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)#start from 0 -random_state=0 , we get the same train and test sets across different executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58626466-de8f-486b-8ad5-f724f503db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6044b-262f-449a-b463-c6a8bd779183",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b5f5c-5893-40a9-8600-80780ae2a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e8151-915e-4600-9d9d-626bea442b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e36e2-f2a3-43a9-aa56-8c7b431c0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5cadd-49f6-4230-ab10-22da2fce9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062acd6e",
   "metadata": {},
   "source": [
    "# STANDARDIZATION/SCALING\n",
    "# DISTANCE-BASED Algorithm is sensitive to data distribution. It is necessary to scale the data. Let's try scaling with MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0b6807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMaxScaller will return the data between 0-1\n",
    "#Transform features by scaling each feature to a given range.\n",
    "#This estimator scales and translates each feature individually such that it is in the given range on the training set,\n",
    "#e.g. between zero and one.\n",
    "\n",
    "#The fit(data) method is used to compute the mean and std dev for a given feature so that it can be used further for scaling.\n",
    "#The transform(data) method is used to perform scaling using mean and std dev calculated using the .fit() method.\n",
    "#The fit_transform() method does both fit and transform.\n",
    "\n",
    "# Fit the scaler on the training data and transform it-for KNN only scale the features(X_train,X_test) not the label/target(y_train,y_test)-label in iris dataset is categorical 0,1,2-no need scaling\n",
    "# Apply the same transformation to the test data (without fitting again!)-test data is used to test the model -it is unseen data-do not fit the scaler on the test data to avoid data leakage.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler=MinMaxScaler()\n",
    "#X_scale_train=scaler.fit_transform(X_train)\n",
    "#X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea789c1d-8d25-4f9b-89e6-a492422a50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same transformation to the test data (without fitting again!)-test data is used to test the model -it is unseen data-do not fit the scaler on the test data to avoid data leakage.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler=MinMaxScaler()\n",
    "#X_scale_test=scaler.fit_transform(X_test)\n",
    "#X_scale_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4c4e8",
   "metadata": {},
   "source": [
    "# Fitting and Evaluating the Model\n",
    "# KNN CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "117d0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first line creates an instance of the KNeighborsClassifier class with the parameter n_neighbors set to 3.\n",
    "# This means that the classifier will consider the 3 nearest neighbors when making predictions.\n",
    "# The second line fits the classifier to the training data X_scale_train and y_train.\n",
    "#This means that the classifier will learn from the training data(scale) and be able to make predictions on new data.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = knn.fit(X_scale_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d6c0f6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The knn object is assumed to have been previously defined and trained on a training dataset.\n",
    "# The predict method of the knn object is then called with the X_test (scale) dataset as input.\n",
    "# This returns an array of predicted class labels for each sample in X_test, which is assigned to the variable y_pred.\n",
    "# Overall, this code is used to evaluate the performance of the KNN classifier on a test dataset by comparing the predicted labels to the true labels.\n",
    "y_pred = knn.predict(X_scale_test)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f612d8",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "82593ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#calculates the accuracy of a machine learning model by comparing the predicted values \n",
    "#(stored in y_pred) with the actual values (stored in y_test).\n",
    "from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70d1dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A classification report is used to measure the quality of predictions from a classification algorithm. \n",
    "#It details how many predictions are true and how many are false\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "#report = classification_report(y_test, y_pred)\n",
    "#print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a87b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
